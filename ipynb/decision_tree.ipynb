{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "This example shows how to use [SciKit-Learn](https://scikit-learn.org/stable/) to train a Decision Tree model on the Titanic dataset. Data is processed to increase the accuracy of the model. For a more detailed explanation of what is Decision Tree is, see [Decision Tree](../document/decision_tree.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.text import Annotation\n",
    "from numpy import ndarray\n",
    "from polars import DataFrame, LazyFrame\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "from seaborn import heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the Preprocessed Data\n",
    "\n",
    "The data is preprocessed in the [Data Preprocessing](./data_preprocessing.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xs: LazyFrame = pl.scan_csv(\"../data/train_Xs.csv\")\n",
    "train_ys: LazyFrame = pl.scan_csv(\"../data/train_ys.csv\")\n",
    "test_Xs: LazyFrame = pl.scan_csv(\"../data/test_Xs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X: ndarray[Any, Any] = train_Xs.collect().to_numpy()\n",
    "y: ndarray[Any, Any] = train_ys.collect().to_numpy()\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the Best Parameters (Optional)\n",
    "\n",
    "Use a grid search to find the best parameters for the Decision Tree model. I found that this is sub-optimal and that a simple `DecisionTreeClassifier(max_depth=3)` works best as the Decision Tree seems to over-fit on the training and validation data.\n",
    "\n",
    "It remains an interesting exercise to find the (not) best parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid: dict[str, list[int]] = {\n",
    "    \"max_depth\": [2, 3, 4, 5, 6],\n",
    "    \"max_features\": [3, 4, 5, 6, 7, 8, 9],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [2, 5, 10],\n",
    "    \"random_state\": [7, 19, 37, 53, 73],\n",
    "}\n",
    "\n",
    "template_dtc = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(template_dtc, param_grid=parameter_grid, cv=10, scoring=\"accuracy\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtc: DecisionTreeClassifier = grid_search.best_estimator_\n",
    "best_dtc.fit(X_train, y_train)\n",
    "dtc: DecisionTreeClassifier = best_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=3)\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(font_scale=2, rc={\"figure.figsize\": (40, 20)})\n",
    "tree_plot: list[Annotation] = tree.plot_tree(\n",
    "    dtc,\n",
    "    feature_names=train_Xs.collect_schema().names(),\n",
    "    class_names=True,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    proportion=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the decision tree to a dot file\n",
    "# dot_data = tree.export_graphviz(\n",
    "#     clf,\n",
    "#     out_file=\"resource/decision-tree.dot\",\n",
    "#     feature_names=train_features.columns,\n",
    "#     class_names=[\"0\", \"1\"],\n",
    "#     filled=True,\n",
    "#     rounded=True,\n",
    "#     special_characters=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalue the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred: ndarray = dtc.predict(X_validate)\n",
    "accuracy: float = accuracy_score(y_validate, y_pred)\n",
    "precision: float = precision_score(y_validate, y_pred)\n",
    "recall: float = recall_score(y_validate, y_pred)\n",
    "f1: float = f1_score(y_validate, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {100 * accuracy:.2f}%\")\n",
    "print(f\"Precision: {100 * precision:.2f}%\")\n",
    "print(f\"Recall: {100 * recall:.2f}%\")\n",
    "print(f\"F1: {100 * f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.axes_style(rc={\"xtick.top\": True, \"axes.spines.top\": True})\n",
    "\n",
    "confusion: ndarray = confusion_matrix(y_validate, y_pred)\n",
    "\n",
    "plot: Axes = heatmap(\n",
    "    confusion, annot=True, fmt=\"d\", xticklabels=[\"Foundered\", \"Survived\"], yticklabels=[\"Foundered\", \"Survived\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions: ndarray = dtc.predict(test_Xs.collect().to_numpy())\n",
    "prediction_list = pl.DataFrame(\n",
    "    {\n",
    "        \"PassengerId\": pl.Series(range(892, 1310)),\n",
    "        \"Survived\": pl.Series(predictions),\n",
    "    }\n",
    ")\n",
    "prediction_list.write_csv(\"../data/decision_tree_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the Predictions with the Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "source = pl.read_csv(\"../data/decision_tree_predictions.csv\")\n",
    "target = pl.read_csv(\"../data/gender_submission.csv\")\n",
    "\n",
    "y_source = source[\"Survived\"]\n",
    "y_target = target[\"Survived\"]\n",
    "\n",
    "num_differences = (y_source != y_target).sum()\n",
    "num_difference_percentage = (num_differences / len(y_source)) * 100\n",
    "num_difference_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Go back to [index](_index.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
