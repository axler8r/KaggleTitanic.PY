{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "This example shows how to use [SciKit-Learn](https://scikit-learn.org/stable/) to train a Random Forest ensamble model on the Titanic dataset. Data is processed to increase the accuracy of the model. For a more detailed explanation of what is Random Forest is, see [Random Forest](../doc/random_forest.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from matplotlib.axes import Axes\n",
    "from numpy import ndarray\n",
    "from polars import LazyFrame\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "from seaborn import heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the Preprocessed Data\n",
    "\n",
    "The data is preprocessed in the [Data Preprocessing](./data_preprocessing.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xs: LazyFrame = pl.scan_csv(\"../data/train_Xs.csv\")\n",
    "train_ys: LazyFrame = pl.scan_csv(\"../data/train_ys.csv\")\n",
    "test_Xs: LazyFrame = pl.scan_csv(\"../data/test_Xs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs: ndarray[Any, Any] = train_Xs.collect().to_numpy()\n",
    "ys: ndarray[Any, Any] = train_ys.collect().to_numpy()\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(Xs, ys, test_size=0.2, random_state=73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the Best Parameters (Optional)\n",
    "\n",
    "Use a grid search to find the best parameters for the Decision Tree model. I found that this is sub-optimal and that a simple `DecisionTreeClassifier(max_depth=3)` works best as the Decision Tree seems to over-fit on the training and validation data.\n",
    "\n",
    "It remains an interesting exercise to find the (not) best parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid: dict[str, list[int]] = {\n",
    "    \"n_estimators\": [500, 1000, 2000],\n",
    "    \"max_features\": [4, 5, 6],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"min_samples_split\": [2, 3],\n",
    "    # \"min_samples_leaf\": [2, 5, 10],\n",
    "    # \"random_state\": [37, 53, 73],\n",
    "}\n",
    "\n",
    "template_rfc = RandomForestClassifier()\n",
    "os.environ[\"POLARIS_ALLOW_FORKING_THREADS\"] = \"1\"\n",
    "grid_search = GridSearchCV(template_rfc, param_grid=parameter_grid, cv=10, scoring=\"accuracy\", n_jobs=16)\n",
    "del os.environ[\"POLARIS_ALLOW_FORKING_THREADS\"]\n",
    "grid_search.fit(X_train, y_train.ravel())\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rfc: RandomForestClassifier = grid_search.best_estimator_\n",
    "rfc: RandomForestClassifier = best_rfc.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalue the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred: ndarray = rfc.predict(X_validate)\n",
    "accuracy: float = accuracy_score(y_validate, y_pred)\n",
    "precision: float = precision_score(y_validate, y_pred)\n",
    "recall: float = recall_score(y_validate, y_pred)\n",
    "f1: float = f1_score(y_validate, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {100 * accuracy:.2f}%\")\n",
    "print(f\"Precision: {100 * precision:.2f}%\")\n",
    "print(f\"Recall: {100 * recall:.2f}%\")\n",
    "print(f\"F1: {100 * f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.axes_style(rc={\"xtick.top\": True, \"axes.spines.top\": True})\n",
    "\n",
    "confusion: ndarray = confusion_matrix(y_validate, y_pred)\n",
    "\n",
    "plot: Axes = heatmap(\n",
    "    confusion, annot=True, fmt=\"d\", xticklabels=[\"Foundered\", \"Survived\"], yticklabels=[\"Foundered\", \"Survived\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Prediction List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions: ndarray = rfc.predict(test_Xs.collect().to_numpy())\n",
    "prediction_list = pl.DataFrame(\n",
    "    {\n",
    "        \"PassengerId\": pl.Series(range(892, 1310)),\n",
    "        \"Survived\": pl.Series(predictions),\n",
    "    }\n",
    ")\n",
    "prediction_list.write_csv(\"../data/random_forest_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the Predictions with the Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "source = pl.read_csv(\"../data/random_forest_predictions.csv\")\n",
    "target = pl.read_csv(\"../data/gender_submission.csv\")\n",
    "\n",
    "y_source = source[\"Survived\"]\n",
    "y_target = target[\"Survived\"]\n",
    "\n",
    "num_differences = (y_source != y_target).sum()\n",
    "num_difference_percentage = (num_differences / len(y_source)) * 100\n",
    "num_difference_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
